{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"i512jkwfT0UZ","executionInfo":{"status":"ok","timestamp":1684724028049,"user_tz":-180,"elapsed":3968,"user":{"displayName":"Grantas Bičiulaitis","userId":"11886115887689804485"}}},"outputs":[],"source":["import pandas as pd\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n","from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n","from tensorflow.keras.applications import ConvNeXtTiny\n","from tensorflow.keras.optimizers import Adam\n","import tensorflow as tf\n","\n","import math\n","import os\n","import pickle"],"id":"i512jkwfT0UZ"},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yz6zdd7dowrO","executionInfo":{"status":"ok","timestamp":1684724045397,"user_tz":-180,"elapsed":17351,"user":{"displayName":"Grantas Bičiulaitis","userId":"11886115887689804485"}},"outputId":"5f8c4896-ccab-4846-ccaa-65c6384142f7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"yz6zdd7dowrO"},{"cell_type":"code","execution_count":6,"metadata":{"id":"LgkU3tNvWJDC","executionInfo":{"status":"ok","timestamp":1684724059472,"user_tz":-180,"elapsed":250,"user":{"displayName":"Grantas Bičiulaitis","userId":"11886115887689804485"}}},"outputs":[],"source":["mainPath = \"/content/drive/MyDrive/Bakalaurinis/Dataset/\"\n","# mainPath = \"./dataset/\"\n","trainPath = mainPath + \"train_images/\"\n","train_labels = pd.read_csv(mainPath + \"train.csv\")"],"id":"LgkU3tNvWJDC"},{"cell_type":"code","execution_count":8,"metadata":{"id":"3J3uJZi82ILD","executionInfo":{"status":"ok","timestamp":1684724061110,"user_tz":-180,"elapsed":1,"user":{"displayName":"Grantas Bičiulaitis","userId":"11886115887689804485"}}},"outputs":[],"source":["BATCH_SIZE = 16\n","STEPS_PER_EPOCH = math.floor(len(train_labels)*0.8 / BATCH_SIZE)\n","VALIDATION_STEPS = math.floor(len(train_labels)*0.2 / BATCH_SIZE)\n","EPOCHS = 20\n","TARGET_SIZE = 512"],"id":"3J3uJZi82ILD"},{"cell_type":"code","execution_count":9,"metadata":{"id":"ykRQ0hM-2inj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684724165443,"user_tz":-180,"elapsed":102149,"user":{"displayName":"Grantas Bičiulaitis","userId":"11886115887689804485"}},"outputId":"ff164f36-fd23-44bf-87ef-26ce5e7291f8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 17118 validated image filenames belonging to 5 classes.\n","Found 4279 validated image filenames belonging to 5 classes.\n"]}],"source":["train_labels.label = train_labels.label.astype('str')\n","\n","train_generator = ImageDataGenerator(validation_split = 0.2,\n","                                     preprocessing_function = None,\n","                                     zoom_range = 0.2,\n","                                     cval = 0.2,\n","                                     horizontal_flip = True,\n","                                     vertical_flip = True,\n","                                     fill_mode = 'nearest',\n","                                     shear_range = 0.2,\n","                                     height_shift_range = 0.2,\n","                                     width_shift_range = 0.2) \\\n","    .flow_from_dataframe(train_labels,\n","                         directory = trainPath,\n","                         subset = \"training\",\n","                         x_col = \"image_id\",\n","                         y_col = \"label\",\n","                         target_size = (TARGET_SIZE, TARGET_SIZE),\n","                         batch_size = BATCH_SIZE,\n","                         class_mode = \"sparse\")\n","\n","validation_generator = ImageDataGenerator(validation_split = 0.2) \\\n","    .flow_from_dataframe(train_labels,\n","                         directory = trainPath,\n","                         subset = \"validation\",\n","                         x_col = \"image_id\",\n","                         y_col = \"label\",\n","                         target_size = (TARGET_SIZE, TARGET_SIZE),\n","                         batch_size = BATCH_SIZE,\n","                         class_mode = \"sparse\")"],"id":"ykRQ0hM-2inj"},{"cell_type":"code","execution_count":10,"metadata":{"id":"VmSdfKJGVpSl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684724169205,"user_tz":-180,"elapsed":3765,"user":{"displayName":"Grantas Bičiulaitis","userId":"11886115887689804485"}},"outputId":"f75cf72a-f4bd-417f-de05-a45df14540d7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/convnext/convnext_tiny_notop.h5\n","111650432/111650432 [==============================] - 1s 0us/step\n"]}],"source":["base_model = ConvNeXtTiny(weights='imagenet', include_top=False, input_shape=(TARGET_SIZE, TARGET_SIZE, 3))\n","layers = base_model.output\n","layers = GlobalAveragePooling2D()(layers)\n","predictions = Dense(5, activation='softmax')(layers)\n","model = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)\n","model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"],"id":"VmSdfKJGVpSl"},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1684724169205,"user":{"displayName":"Grantas Bičiulaitis","userId":"11886115887689804485"},"user_tz":-180},"id":"3P4cAqlw71CC","outputId":"c6f45d7f-00f6-44b9-b30e-40a164c48f54"},"outputs":[{"output_type":"stream","name":"stdout","text":["Learning rate before first fit: 0.001\n"]}],"source":["print(\"Learning rate before first fit:\", model.optimizer.learning_rate.numpy())"],"id":"3P4cAqlw71CC"},{"cell_type":"code","execution_count":null,"metadata":{"id":"b824a8f4-37ee-4c84-bf57-cbb8df5b2b46"},"outputs":[],"source":["print(tf.config.list_physical_devices('GPU'))"],"id":"b824a8f4-37ee-4c84-bf57-cbb8df5b2b46"},{"cell_type":"code","execution_count":null,"metadata":{"id":"vb7aK7ShaeiW"},"outputs":[],"source":["model_save = ModelCheckpoint(os.path.join(mainPath, 'ConvNeXtTiny.h5'), \n","                             save_best_only = True, \n","                             monitor = 'val_loss', \n","                             mode = 'min', verbose = 1)\n","reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.3, \n","                              patience = 1, min_delta = 0.001, \n","                              mode = 'min', verbose = 1)\n","early_stop = EarlyStopping(monitor='val_loss', patience=2, mode='min', verbose=1)\n","\n","\n","history = model.fit(\n","    train_generator,\n","    steps_per_epoch = STEPS_PER_EPOCH,\n","    epochs = EPOCHS,\n","    validation_data = validation_generator,\n","    validation_steps = VALIDATION_STEPS,\n","    callbacks = [model_save, reduce_lr, early_stop]\n",")"],"id":"vb7aK7ShaeiW"},{"cell_type":"code","execution_count":null,"metadata":{"id":"MvLV0-CPmdfX"},"outputs":[],"source":["model.save(os.path.join(mainPath, 'ConvNeXtTinyFinal'))\n","\n","with open(os.path.join(mainPath, 'ConvNeXtTinyHistory.pkl'), 'wb') as f:\n","    pickle.dump(history.history, f)"],"id":"MvLV0-CPmdfX"}],"metadata":{"colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}